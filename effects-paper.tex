\documentclass{article}

\usepackage[top=2in, bottom=1.5in, left=1.7in, right=1.5in]{geometry}

\usepackage{listings}
\usepackage{color}
\usepackage{amsmath}
\usepackage{stmaryrd}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{gb4e}
\usepackage{bussproofs}


\newcommand{\dand}{\mathbin{\bar{\land}}}
\newcommand{\dnot}{\mathop{\bar{\lnot}}}
\newcommand{\dimpl}{\mathbin{\bar{\to}}}
\newcommand{\dexists}{\mathop{\bar{\exists}}}
\newcommand{\dforall}{\mathop{\bar{\forall}}}

\newcommand{\hsbind}{\mathbin{\texttt{>>=}}}
\newcommand{\hsrevbind}{\mathbin{\texttt{=<<}}}
\newcommand{\hsseq}{\mathbin{\texttt{>>}}}
\newcommand{\occons}{\mathbin{::}}

\newcommand{\statecps}[3]{\llbracket #3 \rrbracket^{#2}_{#1}}
\newcommand{\cps}[2]{\llbracket #2 \rrbracket^{#1}}

\newcommand{\sem}[1]{\llbracket #1 \rrbracket}
\newcommand{\intens}[1]{\overline{#1}}

\def\limp {\mathbin{{-}\mkern-3.5mu{\circ}}}

\title{Algebraic Effects and Handlers \\ in Natural Language Interpretation}

\begin{document}

\maketitle

\begin{abstract}
  Phenomena on the syntax-semantics interface of natural languages have been
  observed to have links with programming language semantics, namely
  computational effects and evaluation order. We explore this connection to be
  able to profit from recent development in the study of effects. We propose
  adopting algebraic effects and handlers as tools for facilitating a uniform
  and integrated treatment of different non-compositional phenomena on the
  syntax-semantics interface.

  In this extended abstract, we give an exposition of the framework of
  algebraic effects and handlers with an eye towards its applicability in
  computational semantics. We then present some exemplary analyses in the
  framework: we study the interplay of anaphora and quantification by
  translating the continuation-based dynamic logic of de Groote into something
  more resemblant of DRT and we propose a treatment of overt wh-movement which
  avoids higher-order types in the syntax.
\end{abstract}

\section{Several Isolated Treatments}

In the formal study of the syntax-semantics interface, researchers try to
discover a systematic translation from the syntactic structures of utterances
to their denotations. This translation is often performed indirectly by
translating the syntactic structure into a meta-language of semantic
representations. For the sake of discussion, we rely on this method as
well. We will be studying the challenges of translating syntactic structures
to formulas of Church's higher-order logic.

A systematic account of the syntax-semantics interface should be
compositional, i.e. the denotations of complex utterances should be functions
of the utterances' constituents and their manners of composition. In the style
of abstract categorial grammars, we take our syntactic structures to be
$\lambda$-terms and we demand that the translation from syntax to semantics be
a homomorphism. This means that we view the syntactic structure as a program
and our goal in studying the syntax-semantics interface is to find suitable
definitions/interpretations for the constructs of the language this program is
written in. To describe the process of building up and gluing together the
semantic representation, we will use a meta-language also. The language used
is often the same as the language of the semantic representations,
i.e. $\lambda$-calculus, which makes the boundary between the two quite
blurry.

Work in this paradigm has focused on phenomena that seem to defy the widely
accepted principle of compositionality. We will consider several examples of
such work now by looking at the case of a ``simple'' transitive verb and the
different kinds of denotations that semanticists have assigned it to work
around different problems. Namely, we will focus on in-situ quantification and
anaphora. However, similar phenomena could also have been demonstrated on
treatments of implicit arguments \citep{blom2012implicit} or events
\citep{qian2011event}.

\begin{exe}
  \ex \label{ex:simple} Mary read \emph{Ulysses}. \\
  $\textbf{read}(\textbf{Mary}, \textbf{Ulysses})$
\end{exe}

In example \eqref{ex:simple}, the translation from syntax to semantics is
trivial. NPs become individuals and transitive verbs become binary relations
on individuals.

\subsection{In-situ quantification}

\begin{exe}
  \ex \label{ex:quantification} Mary read every book. \\
  $\forall x. \textbf{book}(x) \to \textbf{read}(\textbf{Mary}, x)$
\end{exe}

In deriving the semantic contents of \eqref{ex:quantification}, the universal
quantifier and implication contributed by the quantificational noun phrase
scope over, and take as arguments, the contributions of the verb and the
subject.

One way to cop out of solving the problem of in-situ quantification is to just
bend syntax and say that the syntactic structure of \eqref{ex:quantification}
is in fact the following:

$$
\textsc{every} \ \textsc{book} \ (\lambda x. \textsc{read} \ \textsc{Mary} \ x)
$$

However, we can keep the original syntactic structure by changing the
definition of \textsc{read}, i.e. the way \textsc{read} glues its arguments
into a semantic representation.\footnote{As in Church's Simple Type Theory, we
  use $\iota$ for the type of individuals and $o$ for the type of
  propositions.}

\begin{align*}
  \sem{\textsc{read}} & : ((\iota \to o) \to o) \to ((\iota \to o) \to o) \to
  o \\
  \sem{\textsc{read}} & = \lambda s o. s (\lambda x. o (\lambda
  y. \textbf{read}(x, y)))
\end{align*}

One way to look at this is to say that NPs denote generalized quantifiers
(type $(\iota \to o) \to o$) and that transitive verbs are relations on
generalized quantifiers. We can also think of this change as introducing
control effects (continuations) into our glue language
\citep{barker2002continuations}. NPs can now have non-local effects on the
construction of the semantic representation by taking scope over their
continuations. The new $\sem{\textsc{read}}$ is just the result of
(selectively) CPS-transforming the previous $\lambda s o. \textbf{read}(s,
o)$.

\subsection{Anaphora}
\label{ssec:anaphora}

\begin{exe}
  \ex \label{ex:anaphora} Mary$_1$ read her$_1$ favorite book. \\
  $\textbf{read}(\textbf{Mary}, \textbf{favorite-book}(\textbf{Mary}))$
\end{exe}

In order to interpret \eqref{ex:anaphora}, we need to link the antecedent with
the anaphoric pronoun since one is not a constituent of the other but the
semantic representation of the latter is dependent on that of the former. In
accordance with dynamic semantics \citep{kamp1993discourse}, we can analyze
this by positing a store into which discourse referents are introduced and
from which they are later retrieved. This boils down to extending our glue
language with state. This is the strategy employed in the continuation-based
dynamic logic of \citet{de2006towards}. The type of NP denotations becomes in
turn more complex to reflect the fact that NPs can access the current state
and manipulate their continuations:

$$
\sem{np} = (\iota \to \gamma \to (\gamma \to o) \to o) \to \gamma \to (\gamma
\to o) \to o
$$

The first argument (type $\iota \to \gamma \to (\gamma \to o) \to o$) corresponds
to a continuation delimited by the containing tensed clause, the second
argument (type $\gamma$) is the context, where we find e.g. the available
discourse referents, and the third argument (type $\gamma \to o$) corresponds
to an open-ended discourse-wide continuation. The context is what lets us
implement anaphora while the two different continuations serve to enforce DRT
accessibility constraints \citep{kamp1993discourse} (e.g. the universal
quantifier in \emph{everyone} provides a referent and takes scope only over
the containing clause while the existential quantifier in \emph{someone}
scopes over and provides a referent even for following clauses).

What denotation does this theory assign to the transitive verb
\emph{read}?\footnote{$\bar{o}$, a dynamic proposition, is shorthand for
  $\gamma \to (\gamma \to o) \to o$, where $\gamma$ is the state, i.e. the
  referent store, and $\gamma \to o$ is the continuation.}

\begin{align*}
  \sem{\textsc{read}} & : \sem{np} \to \sem{np} \to \sem{s} \\
  \sem{\textsc{read}} & : ((\iota \to \bar{o}) \to \bar{o}) \to
                          ((\iota \to \bar{o}) \to \bar{o}) \to
                          \bar{o} \\
  \sem{\textsc{read}} & : ((\iota \to \gamma \to (\gamma \to o) \to o)
                           \to \gamma \to (\gamma \to o) \to o) \\ & \to
                          ((\iota \to \gamma \to (\gamma \to o) \to o)
                           \to \gamma \to (\gamma \to o) \to o) \\ & \to
                           \gamma \to (\gamma \to o) \to o \\
  \sem{\textsc{read}} & = \lambda s o. s (\lambda x. o (\lambda y e
  \phi. \textbf{read}(x, y) \land \phi e))
\end{align*}

Again, we can interpret the theory several ways. One can say that
\textsc{read} has now become a dynamic relation on generalized dynamic
quantifiers. We also propose another view. Instead of considering the dynamic
proposition $\bar{o}$ as a semantic representation, we can see it as an
effectful computation\footnote{In a sense similar to the notions of
  computation of \citet{moggi1991notions} , popularized as the monads of
  functional programming.}, that accesses some anaphoric state and manipulates
continuations, to produce a term of type $o$, the final semantic
representation.

%% \subsection{Implicit Arguments}

%% \begin{exe}
%%   \ex \label{ex:implicit} Mary read. \\
%%   $\exists x. \textbf{read}(\textbf{Mary}, x)$
%% \end{exe}



%% \subsection{Event Arguments}

%% \begin{exe}
%%   \ex \label{ex:event} Mary read \emph{Ulysses} with pleasure. \\
%%   $\exists e. \textbf{read}(e, \textbf{Mary}, \textbf{Ulysses}) \land \textbf{with-pleasure}(e)$
%% \end{exe}


%% \begin{exe}
%%   \ex \label{ex:presupposition} If Mary has a cat, she reads \emph{Ulysses} to
%%   her cat. \\
%%   $\forall x. (\textbf{cat}(x) \land \textbf{has}(\textbf{Mary}, x)) \to (\textbf{reads}(\textbf{Mary})$
%%   \ex \label{ex:complicated} Mary would gladly re-read all her favorite books in her garden, if she actually had one.
%% \end{exe}

\section{Computation on the Syntax-Semantics Frontier}

In the preceding examples, we have seen that seemingly non-compositional
phenomena can be accounted for by admitting some sort of effect into our glue
language. If we go back to the metaphor of our syntactic structures being
programs that evaluate to their semantic representations, it seems that the
language these programs are written in exhibits a lot of effects. In the
previous chapters, we have seen state and continuations, but a look at
implicit arguments and events would lead us to also consider partiality and
environment-dependence, respectively.

Our chief motivation is to unite the treatments presented in the previous
section and to start formalizing the interactions between the phenomena
treated therein. Since effects are an intensely-studied topic in formal
semantics of programming languages and calculi, it would be convenient to
employ a glue language equipped with some notion of effects.

Choosing a language with some fixed set of side effects (such as some
general-purpose programming language) would not be practical since as we have
seen, new treatments of discovered phenomena usually rely on new effects. We
would therefore prefer a framework that allows us to abstract over the
different effects in our glue language.

One such framework are the notions of computation of
\citet{moggi1991notions}, rendered as monads in category theory and used
heavily in popular functional programming. \citet{shan2002monads} already
examined the potential of a monadic framework for studying the various effects
he observed in existing linguistic analyses. However, in his study, he points
out that combining different monads is a difficult problem which still lacks a
satisfying solution (see references in \cite{shan2002monads} and
\citet{kammar2013handlers}).

A compelling alternative to the use of monads to describe effects has gained
popularity recently (\citet{bauer2012programming}, \citet{kammar2013handlers},
\citet{kiselyov2013extensible}). This new approach is rooted in the algebraic
study of effects and handlers by \citet{plotkin2009handlers} that builds on
the notion of Lawvere theory, which provides a category-theoretical take on
universal algebra different from the one offered by monads
\citep{hyland2007category}. In our paper, we argue that algebraic effects can
solve some of our problems in combining multiple effects in a single glue
language and that the dual notion, handlers, can be identified in existing
linguistic treatments and is a natural fit for our task.


\section{The Case for Effects and Handlers}

In the algebraic effects framework, we use a calculus with abstract effectful
operations as language primitives. \citep{kammar2013handlers}

\begin{prooftree}
  \AxiomC{$(op : A \to B) \in E$}
  \AxiomC{$\Gamma \vdash V : A$}
  \AxiomC{$\Gamma, x : B \vdash_E M : C$}
  \TrinaryInfC{$\Gamma \vdash_E op\ V (\lambda x. M) : C$}
\end{prooftree}

We take $op$ to be an abstract operation with argument type $A$ and result
type $B$. We can then invoke this operation by providing it with an argument
of the correct type and a continuation which will receive the result of the
operation and carry out the rest of the computation.

What is of note in the above judgments is the $E$ subscript. Typing judgments
for computations not only serve to prove that a computation will finish by
yielding a value of some type (given after the colon), but they also guarantee
us that the computation will restrict itself to effectful operations contained
in the set $E$.

Such a type system should be familiar to anyone who has ever used Java. As
goes in the Java language specification \citep{gosling2000java}, ``Methods
declare the checked exceptions that can arise from their execution, which
allows compile-time checking to ensure that exceptional conditions are
handled''. We can see the invocation of an operation as throwing a (checked)
exception whose message contains the argument value and the continuation to be
called with the result.

The analogy of operations as exceptions will help us understand the dual
notion of a handler. Handlers behave exactly like exception
handlers. Exception handlers intercept specific types of exceptions to define
how they should be resolved, making use of any content stored in the exception
message. General handlers intercept specific abstract operations to define how
they should be executed, making use of the supplied argument and the callback
continuation. Since general handlers have access to the continuation, they can
resume the computation at the point where the abstract operation was invoked,
whereas exception handlers generally do not and thus discard the failed
computation.\footnote{The Common Lisp condition and restart system also allows
  one to resume the computation when handling an exception. However, the
  continuation available to the handler is not a first-class function and
  cannot be invoked multiple times.}

\subsection{Denotations for Effects}
\label{ssec:denotations-for-effects}

Let us now look at what would be a suitable denotational semantics for a
language with algebraic effects and handlers.

An expression $\Gamma \vdash_E M : C$ can be seen as something that will
either compute directly to the final value of type $C$ or something that will
invoke one of the operations in $E$, providing the operation's argument and a
continuation.\footnote{The idea of seeing a computation as denoting either a
  value or an effect dates back to at least \citet{cartwright1994extensible}.}
Following is a formula for the type of denotation given to a computation of type
$C$ exhibiting effects $E$. \citep{bauer2012programming}
\citep{kiselyov2013extensible}

$$
\sem{C_E} = C + \sum_{(op : A \to B) \in E} A \times \sem{C_E}^B
$$

We can start appreciating some enticing features of this system in comparison
to the prevalent monadic approach.

First of all, the types of computations are decomposed into two components:
the type of the value being computed and the set of effects the computation
can have. This is in contrast with the monadic approach, where both the result
type and the effect meet in a single type, with the monad functor being
applied to the result type.

Let us take the example of a computation of result type $\alpha$ that accesses
some state of type $\gamma$. In the effects framework, this computation would
have type $\alpha_{\left\{get : 1 \to \gamma, put : \gamma \to 1\right\}}$
where $get$ and $put$ are the abstract operations used to read from and write
to the state. In the monadic framework, this computation would be rendered as
$State_\gamma(\alpha)$ which is equal to $\gamma \to \alpha \times \gamma$.

If we then consider extending this computation to include, e.g., exceptions,
we would get the following developments. In the effects framework, we have
$\alpha_{\left\{get : 1 \to \gamma, put : \gamma \to 1, raise : \epsilon \to
  0\right\}}$. In the monadic framework, we have
$Exc_\epsilon(State_\gamma(\alpha))$, which is $(\gamma \to \alpha \times
\gamma) + \epsilon$, or maybe $State_\gamma(Exc_\epsilon(\alpha))$, which is
$\gamma \to (\alpha + \epsilon) \times \gamma$.

If we look at the type of the denotation of the computation in the effects
framework, we see that the different effects sit side-by-side in an unordered
flat collection. The computation is represented as either a value or a request
to perform one of the effectful operations. Any interactions between these
effects are up to the handlers which will interpret this computation.

On the other hand, in the case of the monadic framework, we are forced to
commit from the start to a specific interaction between the two effects. The
representation of the computation is then bound to this specific
interpretation. Furthermore, the two modes of combining the two monadic
effects shown above are not exhaustive. \citet{kiselyov2013extensible} show an
example computation which combines exceptions and non-determinism and that
requires the use of the type $Exc_\epsilon(List(Exc_\epsilon(\alpha)))$.

The structure of the denotations in the effects framework makes it easy to
embed less expressive computations into contexts that employ a wider palette
of effects and to be polymorphic w.r.t. the effects. If we take the example of
a stateful computation in a context that also permits exceptions, then we can
benefit from the fact that $\sem{\alpha_{\left\{get, put\right\}}}$ is a
subset of $\sem{\alpha_{\left\{get, put, raise\right\}}}$ (modulo some trivial
injection). This means we can take expressions and denotations from linguistic
treatments that ignore some linguistic effect and we can plug them directly
into our richer integrated treatment without having to do any adaptation,
lifting or conversion.

More interestingly, we can also do the converse thanks to effect
polymorphism. We can replace any subterm $N_1$ of some term $M$ with another
subterm $N_2$ which has the same type but that also triggers some new
unhandled effects $E$. The resulting term $M'$ will be still well-typed and
the unhandled effects $E$ of $N_2$ will simply propagate to become the
unhandled effects of $M'$. This means that if we have a constituent below
which we need to introduce some effect and above which the effect will be
handled, we are not obliged to modify the denotation of the intervening
constituent. If it has no interaction with the effect, it can remain
agnostic. This is in contrast with the manual style of passing around all the
contextual arguments, states and continuations.

\subsection{Handlers}

Now we examine the notion of a handler. If we look back to the definition of
$\sem{C_E}$ in \ref{ssec:denotations-for-effects}, we see that a computation
is either a value or an effect. We can think of values as constants and of
effects as algebraic operations. More precisely, an effect $op : A \to B$ can
be seen as a family of algebraic operations $op_a$, one for each value $a$ of
type $A$. Each of these operations $op_a$ is a $\left| B \right|$-ary
operation on computations, combining the computations for all the possible
outcomes of the effect into a single computation.

To demonstrate on an example, let us consider an operation for writing strings
to some output channel, $print : \sigma \to 1$. This can be thought of as a
family of unary operations $print_s$ for every string $s$. The meaning of
$print_{hello}(C)$ is then a computation that first prints $hello$ to the
output channel and then carries out the computation $C$. The operator $or : 1
\to 2$ for non-deterministic choice corresponds to a binary operation on
computations such that $or(C_1, C_2)$ is a non-deterministic computation that
continues by either evaluating $C_1$ or $C_2$. This formulation in terms of
algebraic operations on computations is what gave this framework the name
``algebraic effects''.

In light of this algebraic view, it becomes easy to explain handlers. A
handler can be seen as a homomorphism which maps the computation it handles to
another computation by instantiating certain abstract operations within
\citep{plotkin2009handlers} \citep{pretnar2010logic}.

Thinking of handlers as scoped interpretations is instructive. Denotations can
be written using environment-dependent abstract operations such as ``introduce
a new discourse referent (in the current DRS)'', ``access available discourse
referents'', ``access event under discussion'', ``access salient world'',
``scope over the current tensed clause''\ldots

Handlers can then be placed at the appropriate junctions in the syntactic tree
to give meaning to these abstract operations. For example, lexical items that
necessitate a fresh DRS (negation, universal quantification) will carry
handlers for introducing and accessing discourse referents, access to the
event under discussion might be handled at the edge of a scope domain,
modality operators would handle references to the salient world and tensed
clauses will handle the quantifiers' access to their scope to enforce scope
islands.

\section{Applications of Effects and Handlers to Computational Semantics}

Our first inspiration for adopting effects was to bridge the hierarchical
structures of DRSs and the compositional treatment of anaphora in the
continuation-based dynamic logic of \citet{de2006towards}.

\subsection{DRT, Continuations and Effects}

In \citet{de2006towards}, and in more detail in
\citet{lebedeva2012expression}, we can see indefinites introducing some
existential quantifier and adding the variable bound by the quantifier into
the store as a new discourse referent. In our effects framework, we can think
of this complex action as an effect, let us call it $fresh$, whose purpose is
to introduce a new discourse referent at the current point of discourse and
whose implementation will introduce a quantifier someplace and record the
referent in some store. This decomposition into an abstract interface (the
$fresh$ operation which introduces a discourse referent) and specific
implementations that will realize it (handlers for $fresh$) is pertinent. It
gives us another way to explain how it is possible that the same indefinite
expression can sometimes contribute an existential quantifier and sometimes a
universal one, as is the case with the famous example of donkey sentences
\citep{kamp1993discourse}.

Besides introducing discourse referents, lexical items in continuation-based
dynamic logic also access the sum total of the available discourse referents
to be able to resolve anaphora by choosing a salient antecedent from their
ranks. We model this feature by an effect, $get$, which simply lets
computations access the current contents of the discourse store.

With these two operations in hand, we can start rewriting de Groote's
continuation-based dynamic logic. In short: the dynamic existential quantifier
will essentially boil down to a call to $fresh$, dynamic negation will
introduce a handler (a new DRS) and dynamic conjunction will be simple
conjunction (with arguments evaluated left-to-right). By doing this, we can
move the dynamicity of continuation-based dynamic logic into the effects, and
so instead of having the type $(\iota \to \gamma \to (\gamma \to o) \to o) \to
\gamma \to (\gamma \to o) \to o$ for NP denotations, we get $(\iota \to o_E)
\to o_E$ for some set of effects $E$ containing $fresh$ and $get$. Here we see
that we have really translated the notion of a dynamic proposition ($\bar{o} =
\gamma \to (\gamma \to o) \to o$) to the notion of an effectful computation of
a static proposition ($o_E$), as was hinted at in \ref{ssec:anaphora}.

The NP denotations now have type $(\iota \to o_E) \to o_E$, something more
complicated than the naive intuitive $\iota$ one starts with for proper nouns
and other referring expressions and also something that can be seen as a
computation of $\iota$ with access to some continuation of result type
$o_E$. If we look at the denotations, the meaning of this continuation is the
scope over which quantifiers such as \emph{every} should range. This scope is
supplied to the NP by the tensed clause it is contained in. If we were to take
this approach to its logical conclusion, we could turn this into an effect
too. Quantificational noun phrases could employ a $scope\_over$ effect to
introduce some quantifier and tensed clauses could be handlers for these
effects, delimiting the scope of these quantifiers.

We have now arrived at a type for NP denotations that is $\iota_E$, where $E$
is some set of effects including $scope\_over$, $get$ and $fresh$, the three
effects being somewhat analogous to the three arguments that NP denotations
abstract over in continuation-based dynamic logic. However, this type lacks a
result of type $o$ and it becomes impossible to express the propositional
content of NPs, e.g. the restrictor of a quantifier contributed by a noun
combined with a determiner. The fact that NPs assert some propositional
content as well as evaluate to some variable for individuals ($\iota$) can be
modelled by another effect, $assert$. The $assert$ effect is handled by the
same handler as $fresh$ and $get$, i.e. by a DRS.

We have therefore arrived at the following system with two kinds of
handlers. We have DRSs as handlers that handle three effects that can be seen
as the interface of a DRS: we can build up a DRS by introducing new discourse
referents ($fresh$) and constraints ($assert$) and we can use the information
stored inside to resolve anaphora ($get$). We also have tensed clauses as
handlers. They delimit scope islands which define the scopes of the
quantifiers contained within ($scope\_over$).

\subsection{Overt Movement and Effects}

Overt movement (as in the case of an object extracted from a relative clause
by a relativizer such as \emph{who}) has in the categorial school been often
studied as $\lambda$-abstraction or hypothetical reasoning.

$$
\textsc{who} : (np \limp s) \limp n \limp n
$$

Using linear implication for the arrow type lets us enforce that one
relativizer can only cover one trace. However, overt wh-movement has more
restrictions, especially when it comes to multiple extraction
\citep{pogodalla2012controlling}.

When we have effects available to us, we can choose an alternative
solution. Traces can be seen as inaudible NPs whose semantic representation is
computed through an effectful operation, $move$. A relativizer will then
handle $move$ events in the relative clause. The handler will be a shallow
handler \citep{kammar2013handlers}, meaning it will only handle the first
occurrence of the $move$ event that will occur in the relative clause, which
gives correct predictions in the case of multiple extraction.

By making the relativizer handler fail in the case that it does not intercept
any $move$ effect (i.e. the relative clause contained no free trace),
sentences with ungrammatical uses of the relativizer can be ruled out. With
this technique, the type of \textsc{who} becomes $s \limp n \limp n$, which is
interesting because using 2nd order types, such as this one, in the syntax
makes it possible to use efficient parsing algorithms
\citep{kanazawa2007parsing}.


\section{Conclusion}

In this extended abstract, we gave a short exposition to the theory of
algebraic effects and handlers and demonstrated how it can be applied to
computational semantics. Besides our principal example of dynamic logic and
DRT, we also covered extraction. However, that is not the full extent of the
applicability of effects and handlers. The event argument under discussion
\citep{qian2011event} and the salient world are both examples of dynamic
binding, which is a special case of a handler. \citet{lebedeva2012expression}
proposes modeling presuppositions and proper names using exceptions, which are
a trivial case of handlers. The treatment of implicit arguments in
\citet{blom2012implicit} uses an operator which is also a simple exception
handler.

We have not spent much time defending the position that algebraic effects and
handlers facilitate the analysis of \emph{multiple} phenomena in the same
grammar. However, compelling evidence for using algebraic effects and handlers
in contexts that involve multiple computational effects at the same time can
be found in existing literature (e.g. \citet{kiselyov2013extensible},
\citet{cartwright1994extensible}).

For future work, we are interested in developing a simple calculus with
effects and a notion of evaluation order suitable for the study of the
syntax-semantics interface (up until now, experiments were done in \emph{Eff}
\citep{bauer2012programming} and the extensible effects Haskell library of
\citet{kiselyov2013extensible}). Having fixed such a calculus, we would aim to
study non-compositional semantic phenomena in concert, not in isolation, and
to examine their interactions.

% CITE! CBN, Shan

\bibliography{effects-paper}
\bibliographystyle{plainnat}

\end{document}
