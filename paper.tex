\documentclass{article}

\usepackage{listings}
\usepackage{color}
\usepackage{amsmath}
\usepackage{stmaryrd}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{gb4e}

\newcommand{\dand}{\mathbin{\bar{\land}}}
\newcommand{\dnot}{\mathop{\bar{\lnot}}}
\newcommand{\dimpl}{\mathbin{\bar{\to}}}
\newcommand{\dexists}{\mathop{\bar{\exists}}}
\newcommand{\dforall}{\mathop{\bar{\forall}}}

\newcommand{\hsbind}{\mathbin{\texttt{>>=}}}
\newcommand{\hsrevbind}{\mathbin{\texttt{=<<}}}
\newcommand{\hsseq}{\mathbin{\texttt{>>}}}
\newcommand{\occons}{\mathbin{::}}

\newcommand{\statecps}[3]{\llbracket #3 \rrbracket^{#2}_{#1}}
\newcommand{\cps}[2]{\llbracket #2 \rrbracket^{#1}}

\newcommand{\sem}[1]{\llbracket #1 \rrbracket}
\newcommand{\intens}[1]{\overline{#1}}

\title{Algebraic Effects and Handlers \\ in Natural Language Interpretation}

\begin{document}

\maketitle

\section{Multitude of Treatments}

In the formal study of the syntax-semantics interface, researchers try to
discover a systematic translation from the syntactic structures of utterances
to their denotations. This translation is often performed indirectly by
translating the syntactic structure into a meta-language of semantic
representations. For the sake of discussion, we rely on this method as
well. We will be studying the challenges of translating syntactic structures
to formulas of Church's higher-order logic.

A systematic account of the syntax-semantics interface should be
compositional, i.e. the denotations of complex utterances should be functions
of the utterances' constituents and their manner of composition. In the style
of abstract categorial grammars, we take our syntactic structures to be
$\lambda$-terms and we demand that the translation from syntax to semantics be
a homomorphism. This means that we view the syntactic structure as a program
and our goal in studying the syntax-semantics interface is to find suitable
definitions/interpretations for the constructs of the language this program is
written in. To describe the process of building up and gluing together the
semantic representation, we will use a meta-language also. The language used
is often the same as the language of the semantic representations,
i.e. $\lambda$-calculus, which makes the boundary between the two quite
blurry.

Work in this paradigm has focused on phenomena that seem to defy the widely
accepted principle of compositionality. We will consider several examples of
such work now by looking at the case of a ``simple'' transitive verb and the
different kinds of denotations that semanticists have assigned it to work
around different problems.

\begin{exe}
  \ex \label{ex:simple} Mary read \emph{Ulysses}. \\
  $\textbf{read}(\textbf{Mary}, \textbf{Ulysses})$
\end{exe}

In example \eqref{ex:simple}, the translation from syntax to semantics is
trivial. NPs become individuals and transitive verbs become binary relations
on individuals.

\subsection{In-situ quantification}

\begin{exe}
  \ex \label{ex:quantification} Mary read every book. \\
  $\forall x. \textbf{book}(x) \to \textbf{read}(\textbf{Mary}, x)$
\end{exe}

In deriving the semantic contents of \eqref{ex:quantification}, the universal
quantifier and implication contributed by the quantificational noun phrase
scope over, and take as arguments, the contributions of the verb and the
subject.

One way to cop out of solving the problem of in-situ quantification is to just
bend syntax and say that the syntactic structure of \eqref{ex:quantification}
is in fact the following:

$$
\textsc{every} \ \textsc{book} \ (\lambda x. \textsc{read} \ \textsc{Mary} \ x)
$$

However, we can keep the original syntactic structure by changing the
definition of \textsc{read}, i.e. the way \textsc{read} glues its arguments
into a semantic representation.\footnote{As in Church's Simple Type Theory, we
  use $\iota$ for the type of individuals and $o$ for the type of
  propositions.}

\begin{align*}
  \sem{\textsc{read}} & : ((\iota \to o) \to o) \to ((\iota \to o) \to o) \to
  o \\
  \sem{\textsc{read}} & = \lambda s o. s (\lambda x. o (\lambda
  y. \textbf{read}(x, y)))
\end{align*}

One way to look at this is to say that NPs denote generalized quantifiers and
that transitive verbs are relations on generalized quantifiers. We can also
think of this change as introducing control effects (continuations) into our
glue language. NPs can now have non-local effects on the construction of the
semantic representation by taking scope over their continuations. The new
$\sem{\textsc{read}}$ is just the result of (selectively) CPS-transforming the
previous $\lambda s o. \textbf{read}(s, o)$.

\subsection{Anaphora}

\begin{exe}
  \ex \label{ex:anaphora} Mary$_1$ read her$_1$ favorite book. \\
  $\textbf{read}(\textbf{Mary}, \textbf{favorite-book}(\textbf{Mary}))$
\end{exe}

In order to interpret \eqref{ex:anaphora}, we need to link the antecedent with
the anaphoric pronoun since one is not a constituent of the other but the
semantic representation of the latter is dependent on that of the former. In
accordance with dynamic semantics (citation here!), we can analyze this by
positing a store into which discourse referents are introduced and from which
they are later retrieved. This boils down to extending our glue language with
state. This is the strategy employed in de Groote's continuation-based dynamic
logic (cite here). The type of NP denotations becomes in turn more complex to
reflect the fact that NPs can access the current state and manipulate their
continuations:

$$
\sem{np} = (\iota \to \gamma \to (\gamma \to o) \to o) \to \gamma \to (\gamma
\to o) \to o
$$

The first argument corresponds to a continuation delimited by the containing
tensed clause, the second argument (type $\gamma$) is the context, where we
find e.g. the available discourse referents, and the third argument
corresponds to an open-ended discourse-wide continuation. The context is what
lets us implement anaphora while the two different continuations serve to
enforce DRT accessibility constraints (e.g. the universal quantifier in
\emph{everyone} provides a referent and takes scope only over the containing
clause while the existential quantifier in \emph{someone} scopes over and
provides a referent even for following clauses).

What is the denotation of the transitive verb \emph{read} in this treatment
then?\footnote{$\bar{o}$ is shorthand for $\gamma \to (\gamma \to o) \to o$.}

\begin{align*}
  \sem{\textsc{read}} & : \sem{np} \to \sem{np} \to \sem{s} \\
  \sem{\textsc{read}} & : ((\iota \to \bar{o}) \to \bar{o}) \to
                          ((\iota \to \bar{o}) \to \bar{o}) \to
                          \bar{o} \\
  \sem{\textsc{read}} & : ((\iota \to \gamma \to (\gamma \to o) \to o)
                           \to \gamma \to (\gamma \to o) \to o) \\ & \to
                          ((\iota \to \gamma \to (\gamma \to o) \to o)
                           \to \gamma \to (\gamma \to o) \to o) \\ & \to
                           \gamma \to (\gamma \to o) \to o \\
  \sem{\textsc{read}} & = \lambda s o. s (\lambda x. o (\lambda y e
  \phi. \textbf{read}(x, y) \land \phi e))
\end{align*}

Again, we can interpret this several ways. One can say that \textsc{read} has
now become a dynamic relation on generalized dynamic quantifiers. We also
propose another view. Instead of considering the dynamic proposition $\bar{o}$
as a semantic representation, we can see it as an effectful
computation\footnote{In a sense similar to the notions of computation of Moggi
  (cite!), popularized as the monads of functional programming.}, that
accesses some anaphoric state and manipulates continuations, to produce a term
of type $o$, the final semantic representation.

\subsection{Implicit Arguments}

\begin{exe}
  \ex \label{ex:implicit} Mary read. \\
  $\exists x. \textbf{read}(\textbf{Mary}, x)$
\end{exe}



\subsection{Event Arguments}

\begin{exe}
  \ex \label{ex:event} Mary read \emph{Ulysses} with pleasure. \\
  $\exists e. \textbf{read}(e, \textbf{Mary}, \textbf{Ulysses}) \land \textbf{with-pleasure}(e)$
\end{exe}


%% \begin{exe}
%%   \ex \label{ex:presupposition} If Mary has a cat, she reads \emph{Ulysses} to
%%   her cat. \\
%%   $\forall x. (\textbf{cat}(x) \land \textbf{has}(\textbf{Mary}, x)) \to (\textbf{reads}(\textbf{Mary})$
%%   \ex \label{ex:complicated} Mary would gladly re-read all her favorite books in her garden, if she actually had one.
%% \end{exe}

\section{Computation on the Syntax-Semantics Frontier}

In the preceding examples, we have seen that seemingly non-compositional
phenomena can be accounted by admitting some sort of effect into our glue
language. If we go back to the metaphor of our syntactic structures being
programs that evaluate to their semantic representations, it seems that the
language these programs are written in exhibits a lot of effects. In the
previous chapters, we have seen state, continuations, partiality and
environment-dependence.

Our chief motivation is to unite the treatments presented in the previous
section and to start formalizing the interactions between the phenomena
treated therein. Since effects are an intensely-studied topic in formal
semantics of programming languages and calculi, it would be convenient to
employ a glue language equipped with some notion of effects.

Choosing a language with some fixed set of side effects (such as some
general-purpose programming language) would not be practical since as we have
seen, new treatments of discovered phenomena usually rely on new effects. We
would therefore prefer a framework that allows us to abstract over the
different effects in our glue language.

One such framework are Moggi's (CITE!) notions of computation, rendered as
monads in category theory and used heavily in popular functional
programming. Shan (CITE!) already examined the potential of a monadic
framework for studying the various effects he observed in existing linguistic
analyses. However, in his study, he points out that combining different monads
is a difficult problem which still lacks a satisfying solution (see references
in CITE! Shan and CITE! Handlers in Action).

A compelling alternative to the use of monads to describe effects has gained
popularity recently (CITE! Eff, HiA, Oleg, Idris). This new approach is rooted
in the algebraic study of effects and handlers done by Plotkin,
Power... (CITE!). In our paper, we argue that algebraic effects can solve some
of our problems in combining multiple effects in a single glue language and
that the dual notion of handlers can be identified in existing linguistic
treatments and is a natural fit for the task.


\section{The Case for Effects and Handlers}

In the algebraic effects framework, we use a calculus with 

\bibliography{effects-paper}
\bibliographystyle{plainnat}

\end{document}
